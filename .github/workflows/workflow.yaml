# name: 'Terraform CI'

# on:
#   push:
#     branches:
#     - main
#     paths:
#       - '**.tf'
#   pull_request:

# jobs:
#   terraform:
#     name: 'Terraform'
#     runs-on: ubuntu-latest

#     # Use the Bash shell regardless whether the GitHub Actions runner is ubuntu-latest, macos-latest, or windows-latest
#     defaults:
#       run:
#         shell: bash

#     steps:
#     # Checkout the repository to the GitHub Actions runner
#     - name: Checkout
#       uses: actions/checkout@v2

#     # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
#     - name: Setup Terraform
#       uses: hashicorp/setup-terraform@v1


#     # Initialize a new or existing Terraform working directory by creating initial files, loading any remote state, downloading modules, etc.
#     - name: Terraform Init
#       run: terraform init
#       env:
#         GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

#     # Generates an execution plan for Terraform
#     - name: Terraform Plan
#       run: terraform plan -lock=false
#       env:
#         GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

#       # On push to main, build or change infrastructure according to Terraform configuration files
#       # Note: It is recommended to set up a required "strict" status check in your repository for "Terraform Cloud". See the documentation on "strict" required status checks for more information: https://help.github.com/en/github/administering-a-repository/types-of-required-status-checks
#     - name: Terraform Apply
#       if: github.ref == 'refs/heads/main' && github.event_name == 'push'
#       run: terraform apply -auto-approve
#       env:
#         GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}



#################################################################################################
# NOVO JOB DE EXECUÇÃO PARA EXECUTAR A etl-spark/main.py                                        #
#                                                                                               #
# criando um novo JOB para que ele execute somente na pasta etl-spark                           #
# quando tiver mudança no arquivo main.py dessa pasta e sempre quando fizer                     #
# git add , git commit, git push ele trigar esse pipeline CI CD e atualizar no bucket           #
# data-pipeline-jp-combustiveis-brasil-pyspark-code                                             #
#################################################################################################


name: 'Terraform CI'

on:
  push:
    branches:
      - main
    paths:
      - '**.tf'
      - 'etl-spark/main.py'
  pull_request:

jobs:
  terraform:
    name: 'Terraform'
    runs-on: ubuntu-latest

    # Use the Bash shell regardless of the GitHub Actions runner
    defaults:
      run:
        shell: bash

    steps:
      # Checkout the repository to the GitHub Actions runner
      - name: Checkout
        uses: actions/checkout@v2

      # Install the latest version of Terraform CLI and configure the Terraform CLI configuration file with a Terraform Cloud user API token
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v1

      # Initialize a new or existing Terraform working directory
      - name: Terraform Init
        run: terraform init
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      # Generates an execution plan for Terraform
      - name: Terraform Plan
        run: terraform plan -lock=false
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      # On push to main, build or change infrastructure according to Terraform configuration files
      - name: Terraform Apply
        if: github.ref == 'refs/heads/main' && github.event_name == 'push'
        run: terraform apply -auto-approve
        env:
          GOOGLE_CREDENTIALS: ${{ secrets.GOOGLE_CREDENTIALS }}

      # New job to run when main.py changes in etl-spark folder
      etl_spark_job:
        name: 'ETL Spark'
        runs-on: ubuntu-latest

        steps:
          - name: Checkout
            uses: actions/checkout@v2

          # Update the necessary configurations and commands for your ETL Spark job
          - name: Run ETL Spark Job
            run: |
              # Add your ETL Spark commands here
              echo "Running ETL Spark job"
              python etl-spark/main.py




    
        